# -*- coding: utf-8 -*-
"""eda_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16qOmfj6E7UEIXE_CKQHFE6-PQDfmqKkZ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import re
from nltk.corpus import stopwords
import nltk

warnings.filterwarnings('ignore')
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)

sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 6)
colors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#6C5CE7', '#A29BFE']

# Load data
df = pd.read_csv('generative_ai_misinformation_dataset.csv')

print("\n" + "="*80)
print("EXPLORATORY DATA ANALYSIS - MISINFORMATION DETECTION")
print("="*80 + "\n")

print("DATASET OVERVIEW")
print("-"*80)
print(f"Total Posts: {len(df):,}")
print(f"Features: {len(df.columns)}")
print(f"Misinformation: {df['is_misinformation'].sum():,} ({df['is_misinformation'].mean()*100:.1f}%)")
print(f"Authentic: {(df['is_misinformation']==0).sum():,} ({(df['is_misinformation']==0).mean()*100:.1f}%)\n")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

counts = df['is_misinformation'].value_counts().sort_index()
axes[0].bar(['Authentic', 'Misinformation'], counts, color=colors[0:2], edgecolor='black', linewidth=1.5)
axes[0].set_title('Target Distribution', fontsize=13, fontweight='bold')
axes[0].set_ylabel('Number of Posts')
for i, v in enumerate(counts):
    axes[0].text(i, v, str(v), ha='center', va='bottom', fontweight='bold')

axes[1].pie(counts, labels=['Authentic', 'Misinformation'], autopct='%1.1f%%',
            colors=colors[0:2], textprops={'fontsize': 11, 'fontweight': 'bold'})
axes[1].set_title('Class Distribution', fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

#TEXT LENGTH ANALYSIS


print("\nTEXT LENGTH ANALYSIS")
print("-"*80)
print(f"Avg text length: {df['text_length'].mean():.0f} words")
print(f"Range: {df['text_length'].min():.0f} - {df['text_length'].max():.0f} words")
print(f"Misinformation avg: {df[df['is_misinformation']==1]['text_length'].mean():.0f} words")
print(f"Authentic avg: {df[df['is_misinformation']==0]['text_length'].mean():.0f} words\n")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].hist(df['text_length'], bins=50, color=colors[2], edgecolor='black', alpha=0.7)
axes[0].set_title('Text Length Distribution', fontsize=13, fontweight='bold')
axes[0].set_xlabel('Words')
axes[0].set_ylabel('Count')

bp = axes[1].boxplot([df[df['is_misinformation']==0]['text_length'],
                       df[df['is_misinformation']==1]['text_length']],
                      labels=['Authentic', 'Misinformation'], patch_artist=True)
for patch, color in zip(bp['boxes'], colors[0:2]):
    patch.set_facecolor(color)
axes[1].set_title('Text Length Comparison', fontsize=13, fontweight='bold')
axes[1].set_ylabel('Words')

plt.tight_layout()
plt.show()

# SENTIMENT & TOXICITY

print("\nSENTIMENT & TOXICITY")
print("-"*80)
print(f"Avg Sentiment: {df['sentiment_score'].mean():.3f}")
print(f"Avg Toxicity: {df['toxicity_score'].mean():.3f}")
print(f"Misinformation sentiment: {df[df['is_misinformation']==1]['sentiment_score'].mean():.3f}")
print(f"Authentic sentiment: {df[df['is_misinformation']==0]['sentiment_score'].mean():.3f}")
print(f"Misinformation toxicity: {df[df['is_misinformation']==1]['toxicity_score'].mean():.3f}")
print(f"Authentic toxicity: {df[df['is_misinformation']==0]['toxicity_score'].mean():.3f}\n")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

axes[0,0].hist(df['sentiment_score'], bins=50, color=colors[2], edgecolor='black', alpha=0.7)
axes[0,0].set_title('Sentiment Distribution', fontsize=12, fontweight='bold')
axes[0,0].set_xlabel('Sentiment Score')

axes[0,1].hist(df['toxicity_score'], bins=50, color=colors[3], edgecolor='black', alpha=0.7)
axes[0,1].set_title('Toxicity Distribution', fontsize=12, fontweight='bold')
axes[0,1].set_xlabel('Toxicity Score')

for idx, (col, title) in enumerate([(0, 'Sentiment'), (1, 'Toxicity')]):
    bp = axes[1,idx].boxplot([df[df['is_misinformation']==0][f'{["sentiment_score", "toxicity_score"][col]}'],
                              df[df['is_misinformation']==1][f'{["sentiment_score", "toxicity_score"][col]}']],
                             labels=['Authentic', 'Misinformation'], patch_artist=True)
    for patch, color in zip(bp['boxes'], colors[0:2]):
        patch.set_facecolor(color)
    axes[1,idx].set_title(f'{title} Comparison', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.show()

#PLATFORM ANALYSIS

print("\nðŸŒ PLATFORM ANALYSIS")
print("-"*80)
for platform in df['platform'].value_counts().index:
    count = (df['platform'] == platform).sum()
    rate = df[df['platform'] == platform]['is_misinformation'].mean() * 100
    print(f"{platform:10s}: {count:3d} posts ({rate:5.1f}% misinformation)")

print()

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

platform_counts = df['platform'].value_counts()
axes[0].bar(platform_counts.index, platform_counts.values, color=colors[0], edgecolor='black', linewidth=1.5)
axes[0].set_title('Posts by Platform', fontsize=13, fontweight='bold')
axes[0].set_ylabel('Count')
axes[0].tick_params(axis='x', rotation=45)

misinfo_rate = df.groupby('platform')['is_misinformation'].mean() * 100
axes[1].bar(misinfo_rate.index, misinfo_rate.values, color=colors[1], edgecolor='black', linewidth=1.5)
axes[1].set_title('Misinformation Rate by Platform', fontsize=13, fontweight='bold')
axes[1].set_ylabel('Misinformation %')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

#ENGAGEMENT ANALYSIS


print("\nENGAGEMENT ANALYSIS")
print("-"*80)
print(f"Avg Engagement: {df['engagement'].mean():,.0f}")
print(f"Misinformation avg: {df[df['is_misinformation']==1]['engagement'].mean():,.0f}")
print(f"Authentic avg: {df[df['is_misinformation']==0]['engagement'].mean():,.0f}")

ratio = df[df['is_misinformation']==1]['engagement'].mean() / df[df['is_misinformation']==0]['engagement'].mean()
print(f"â†’ Misinformation gets {ratio:.1f}x more engagement\n")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].hist(df['engagement'], bins=50, color=colors[2], edgecolor='black', alpha=0.7)
axes[0].set_title('Engagement Distribution', fontsize=13, fontweight='bold')
axes[0].set_xlabel('Engagement')
axes[0].set_ylabel('Count')

bp = axes[1].boxplot([df[df['is_misinformation']==0]['engagement'],
                       df[df['is_misinformation']==1]['engagement']],
                      labels=['Authentic', 'Misinformation'], patch_artist=True)
for patch, color in zip(bp['boxes'], colors[0:2]):
    patch.set_facecolor(color)
axes[1].set_title('Engagement Comparison', fontsize=13, fontweight='bold')
axes[1].set_ylabel('Engagement')

plt.tight_layout()
plt.show()

#AUTHOR VERIFICATION

print("\nAUTHOR VERIFICATION")
print("-"*80)
verified_pct = (df['author_verified'] == 1).sum() / len(df) * 100
print(f"Verified authors: {verified_pct:.1f}%")
print(f"Verified misinformation rate: {df[df['author_verified']==1]['is_misinformation'].mean()*100:.1f}%")
print(f"Unverified misinformation rate: {df[df['author_verified']==0]['is_misinformation'].mean()*100:.1f}%\n")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

verified_counts = [len(df)-df['author_verified'].sum(), df['author_verified'].sum()]
axes[0].bar(['Unverified', 'Verified'], verified_counts, color=colors[0:2], edgecolor='black', linewidth=1.5)
axes[0].set_title('Author Verification', fontsize=13, fontweight='bold')
axes[0].set_ylabel('Count')

misinfo_by_verified = [df[df['author_verified']==0]['is_misinformation'].mean()*100,
                       df[df['author_verified']==1]['is_misinformation'].mean()*100]
axes[1].bar(['Unverified', 'Verified'], misinfo_by_verified, color=colors[0:2], edgecolor='black', linewidth=1.5)
axes[1].set_title('Misinformation Rate by Author Type', fontsize=13, fontweight='bold')
axes[1].set_ylabel('Misinformation %')
axes[1].set_ylim(0, 100)

plt.tight_layout()
plt.show()

#NLP - WORD ANALYSIS


print("\nNLP - WORD FREQUENCY ANALYSIS")
print("-"*80)

def clean_text(text):
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    return re.sub(r'\s+', ' ', text).strip()

stop_words = set(stopwords.words('english'))
all_words = []

for text in df['text']:
    cleaned = clean_text(text)
    tokens = [w for w in cleaned.split() if w not in stop_words and len(w) > 3]
    all_words.extend(tokens)

word_freq = pd.Series(all_words).value_counts().head(15)
print("Top 15 Most Frequent Words:")
for idx, (word, count) in enumerate(word_freq.items(), 1):
    print(f"  {idx:2d}. {word:15s}: {count:4d} times")

print()

fig, ax = plt.subplots(figsize=(12, 6))
word_freq.plot(kind='barh', ax=ax, color=colors[0], edgecolor='black')
ax.set_title('Top 15 Most Frequent Words', fontsize=13, fontweight='bold')
ax.set_xlabel('Frequency')
ax.invert_yaxis()
plt.tight_layout()
plt.show()

#TF-IDF ANALYSIS

print("\nTF-IDF - IMPORTANT WORDS")
print("-"*80)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=15, stop_words='english')
tfidf_matrix = vectorizer.fit_transform(df['text'])
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())
tfidf_means = tfidf_df.mean().sort_values(ascending=False)

print("Top 15 Most Important Words (TF-IDF):")
for idx, (word, score) in enumerate(tfidf_means.items(), 1):
    print(f"  {idx:2d}. {word:15s}: {score:.4f}")

print()

fig, ax = plt.subplots(figsize=(12, 6))
tfidf_means.sort_values().plot(kind='barh', ax=ax, color=colors[2], edgecolor='black')
ax.set_title('Top Important Words (TF-IDF Score)', fontsize=13, fontweight='bold')
ax.set_xlabel('TF-IDF Score')
plt.tight_layout()
plt.show()

#EMBEDDING SIMILARITY

print("\nSEMANTIC SIMILARITY TO FACTS")
print("-"*80)
print(f"Avg Similarity: {df['embedding_sim_to_facts'].mean():.3f}")
print(f"Misinformation: {df[df['is_misinformation']==1]['embedding_sim_to_facts'].mean():.3f}")
print(f"Authentic: {df[df['is_misinformation']==0]['embedding_sim_to_facts'].mean():.3f}\n")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].hist(df['embedding_sim_to_facts'], bins=50, color=colors[3], edgecolor='black', alpha=0.7)
axes[0].set_title('Similarity Distribution', fontsize=13, fontweight='bold')
axes[0].set_xlabel('Similarity Score')

bp = axes[1].boxplot([df[df['is_misinformation']==0]['embedding_sim_to_facts'],
                       df[df['is_misinformation']==1]['embedding_sim_to_facts']],
                      labels=['Authentic', 'Misinformation'], patch_artist=True)
for patch, color in zip(bp['boxes'], colors[0:2]):
    patch.set_facecolor(color)
axes[1].set_title('Similarity Comparison', fontsize=13, fontweight='bold')

plt.tight_layout()
plt.show()

#CORRELATION ANALYSIS


print("\n FEATURE CORRELATIONS WITH MISINFORMATION")
numeric_df = df.select_dtypes(include=['number'])

if not numeric_df.empty:
    fig, ax = plt.subplots(figsize=(8, 6))
    corr = numeric_df.corr()
    sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f", ax=ax)
    ax.set_title("Feature Correlation Matrix", fontsize=14, weight="bold")
    plt.tight_layout()
    plt.show()
else:
    print("âš  No numeric columns available for correlation analysis\n")

#SUMMARY
print("\nKEY FINDINGS SUMMARY")
print(f"""
1. MISINFORMATION SPREAD
   â€¢ {df['is_misinformation'].mean()*100:.1f}% of posts are misinformation
   â€¢ Gets {ratio:.1f}x more engagement than authentic posts

2. CONTENT PATTERNS
   â€¢ Misinformation: {df[df['is_misinformation']==1]['text_length'].mean():.0f} avg words
   â€¢ Authentic: {df[df['is_misinformation']==0]['text_length'].mean():.0f} avg words
   â€¢ Sentiment - Misinformation more negative/polarized

3. PLATFORM VULNERABILITY
   â€¢ Most affected: {df.groupby('platform')['is_misinformation'].mean().idxmax()} ({df.groupby('platform')['is_misinformation'].mean().max()*100:.1f}%)
   â€¢ Least affected: {df.groupby('platform')['is_misinformation'].mean().idxmin()} ({df.groupby('platform')['is_misinformation'].mean().min()*100:.1f}%)

4. AUTHOR CREDIBILITY
   â€¢ Verified authors post less misinformation
   â€¢ Unverified accounts higher risk

5. NLP INSIGHTS
   â€¢ Specific words indicate misinformation
   â€¢ Text patterns differ significantly
   â€¢ Semantic similarity lower for false claims
""")
